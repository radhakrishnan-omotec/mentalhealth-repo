{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1448850,"sourceType":"datasetVersion","datasetId":849299}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":" **Healthcare Analytics Data**\\\n\n**Prediction of best fit Model and Complete Exploratory Data Analysis**\\\nPerformed by : Ishrat Un Nisa\\\nDated : January 2024\\\nemail : ishratbadar@gmail.com","metadata":{}},{"cell_type":"markdown","source":"## Problem Statement\nRecent Covid-19 Pandemic has raised alarms over one of the most overlooked area to focus: Healthcare Management. While healthcare management has various use cases for using data science, patient length of stay is one critical parameter to observe and predict if one wants to improve the efficiency of the healthcare management in a hospital.\nThis parameter helps hospitals to identify patients of high LOS risk (patients who will stay longer) at the time of admission. Once identified, patients with high LOS risk can have their treatment plan optimized to miminize LOS and lower the chance of staff/visitor infection. Also, prior knowledge of LOS can aid in logistics such as room and bed allocation planning.\nSuppose you have been hired as Data Scientist of HealthMan – a not for profit organization dedicated to manage the functioning of Hospitals in a professional and optimal manner.\nThe task is to accurately predict the Length of Stay for each patient on case by case basis so that the Hospitals can use this information for optimal resource allocation and better functioning. The length of stay is divided into 11 different classes ranging from 0-10 days to more than 100 days.\n# About Dataset\ntrain_data.csv – File containing features related to patient, hospital and Length of stay on case basis\ntrain_data_dictonary.csv – File containing the information of the features in train file\n\nTest Set\ntest_data.csv – File containing features related to patient, hospital. Need to predict the Length of stay for each case_id\n\nSample Submission:\n\ncase_id: Unique id for each case\n\nStay: Length of stay for the patient w.r.t each case id in test data\n\nEvaluation Metric\nThe evaluation metric for this hackathon is 100*Accuracy Score.\n\nAcknowledgements\nMore details can be found on Analytics Vidhya website who conducted the hackathon.\nhttps://datahack.analyticsvidhya.com/contest/janatahack-healthcare-analytics-ii/#ProblemStatement\n\n# Objective:\nExploratory Data Analysis (EDA) to analyze data for checking patterns and getting insight from it\n\nKernel : Python 3.12.1","metadata":{}},{"cell_type":"markdown","source":"## To do list\n1. Import libraries\n2. Load dataset\n3. Analyze and understanding dataset (Anomalies, relationship, missing values, duplicate values etc)\n4. Remove anamolies from data by dealing missing data, duplicate data and other information\n5. Feature engineering\n6. Getting insight from data by applying various techniques \n7. Modeling and predicting ","metadata":{}},{"cell_type":"markdown","source":"# 1. Import following libraries\n - Panadas\n - Numpy\n - Matplotlib\n - Seaborn\n - Scipy","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n# import all relevant libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport scipy as sp\n# To show the plot in the notebook itself instead of opening a new window for the plot\n%matplotlib inline\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:04:58.483572Z","iopub.execute_input":"2024-01-04T11:04:58.484377Z","iopub.status.idle":"2024-01-04T11:05:00.574098Z","shell.execute_reply.started":"2024-01-04T11:04:58.484335Z","shell.execute_reply":"2024-01-04T11:05:00.572346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Load Dataset","metadata":{}},{"cell_type":"code","source":"# load dataset\n# df_train = pd.read_csv('./Data/train_data.csv')\n# df_test = pd.read_csv('./Data/test_data.csv')\ndf_train = pd.read_csv('/kaggle/input/av-healthcare-analytics-ii/healthcare/train_data.csv')\ndf_test = pd.read_csv('/kaggle/input/av-healthcare-analytics-ii/healthcare/test_data.csv')\n\n# To check complete dataset (column wise and row wise)\npd.set_option('display.max_columns', None)    # this is to display all the columns in the dataframe\n# pd.set_option('display.max_rows', None)       # this is to display all the rows in the dataframe","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:00.576197Z","iopub.execute_input":"2024-01-04T11:05:00.576749Z","iopub.status.idle":"2024-01-04T11:05:02.507272Z","shell.execute_reply.started":"2024-01-04T11:05:00.576704Z","shell.execute_reply":"2024-01-04T11:05:02.506013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Analyze data","metadata":{}},{"cell_type":"code","source":"# To check data from training dataset\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:02.508502Z","iopub.execute_input":"2024-01-04T11:05:02.512913Z","iopub.status.idle":"2024-01-04T11:05:02.54956Z","shell.execute_reply.started":"2024-01-04T11:05:02.512862Z","shell.execute_reply":"2024-01-04T11:05:02.548534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# to check details of training dataset\ndf_train.info()","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:02.551842Z","iopub.execute_input":"2024-01-04T11:05:02.55226Z","iopub.status.idle":"2024-01-04T11:05:02.793058Z","shell.execute_reply.started":"2024-01-04T11:05:02.55223Z","shell.execute_reply":"2024-01-04T11:05:02.79203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# Observation 1\n1. The 04 numerical columns are Ids `Hospital_code`, `City_Code_Hospital`, `City_Code_Patient` and `Bed Grade`,\nSo we have to convert them in Strings in both Training and Test datasets \n2. There are some missing values in 02 columns `Bed Grade` and `City_Code_Patient`","metadata":{}},{"cell_type":"code","source":"df_train['Hospital_code'] = df_train['Hospital_code'].astype('str')\ndf_train['City_Code_Hospital'] = df_train['City_Code_Hospital'].astype('str')\ndf_train['Bed Grade'] = df_train['Bed Grade'].astype('Int64')\ndf_train['City_Code_Patient'] = df_train['City_Code_Patient'].astype('str')","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:02.794342Z","iopub.execute_input":"2024-01-04T11:05:02.794678Z","iopub.status.idle":"2024-01-04T11:05:03.347535Z","shell.execute_reply.started":"2024-01-04T11:05:02.794625Z","shell.execute_reply":"2024-01-04T11:05:03.346659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.info()","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:03.35163Z","iopub.execute_input":"2024-01-04T11:05:03.352511Z","iopub.status.idle":"2024-01-04T11:05:03.542142Z","shell.execute_reply.started":"2024-01-04T11:05:03.352477Z","shell.execute_reply":"2024-01-04T11:05:03.540958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train[['City_Code_Patient']].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:03.544036Z","iopub.execute_input":"2024-01-04T11:05:03.544872Z","iopub.status.idle":"2024-01-04T11:05:03.601104Z","shell.execute_reply.started":"2024-01-04T11:05:03.544716Z","shell.execute_reply":"2024-01-04T11:05:03.599899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test['Hospital_code'] = df_test['Hospital_code'].astype('str')\ndf_test['City_Code_Hospital'] = df_test['City_Code_Hospital'].astype('str')\ndf_test['Bed Grade'] = df_test['Bed Grade'].astype('Int64')\ndf_test['City_Code_Patient'] = df_test['City_Code_Patient'].astype('str')","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:03.602469Z","iopub.execute_input":"2024-01-04T11:05:03.602909Z","iopub.status.idle":"2024-01-04T11:05:03.911097Z","shell.execute_reply.started":"2024-01-04T11:05:03.602867Z","shell.execute_reply":"2024-01-04T11:05:03.910044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.info()","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:03.912983Z","iopub.execute_input":"2024-01-04T11:05:03.913404Z","iopub.status.idle":"2024-01-04T11:05:03.99686Z","shell.execute_reply.started":"2024-01-04T11:05:03.913365Z","shell.execute_reply":"2024-01-04T11:05:03.995581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# To check data from test dataset\ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:04.002239Z","iopub.execute_input":"2024-01-04T11:05:04.002648Z","iopub.status.idle":"2024-01-04T11:05:04.02475Z","shell.execute_reply.started":"2024-01-04T11:05:04.002616Z","shell.execute_reply":"2024-01-04T11:05:04.023157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# to check details of test dataset\ndf_test.info()","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:04.026757Z","iopub.execute_input":"2024-01-04T11:05:04.027201Z","iopub.status.idle":"2024-01-04T11:05:04.11009Z","shell.execute_reply.started":"2024-01-04T11:05:04.027161Z","shell.execute_reply":"2024-01-04T11:05:04.108756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check the shape of training and test dataset\nprint('shape of training data set: ', df_train.shape)\nprint('shape of test data set: ', df_test.shape)","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:04.114289Z","iopub.execute_input":"2024-01-04T11:05:04.114902Z","iopub.status.idle":"2024-01-04T11:05:04.120889Z","shell.execute_reply.started":"2024-01-04T11:05:04.114857Z","shell.execute_reply":"2024-01-04T11:05:04.119826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train[['patientid']].nunique()","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:04.122179Z","iopub.execute_input":"2024-01-04T11:05:04.123961Z","iopub.status.idle":"2024-01-04T11:05:04.150865Z","shell.execute_reply.started":"2024-01-04T11:05:04.123919Z","shell.execute_reply":"2024-01-04T11:05:04.14985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# Observation 2\n1. It is noticed that after converting `City_Code_Patient` in string, the missing values  are replaced with 'nan' string\n2. There are more than one records or rows of one patient `patientid` ","metadata":{}},{"cell_type":"code","source":"# Find the Structure or size of Dataset and check the Descriptive Analysis\nprint('Shape of dataset : ',df_train.shape)\ndf_train.describe()","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:04.152515Z","iopub.execute_input":"2024-01-04T11:05:04.153153Z","iopub.status.idle":"2024-01-04T11:05:04.255062Z","shell.execute_reply.started":"2024-01-04T11:05:04.15311Z","shell.execute_reply":"2024-01-04T11:05:04.253914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find the Structure or size of Dataset and check the Descriptive Analysis\nprint('Shape of dataset : ',df_test.shape)\ndf_test.describe()","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:04.256403Z","iopub.execute_input":"2024-01-04T11:05:04.257126Z","iopub.status.idle":"2024-01-04T11:05:04.32398Z","shell.execute_reply.started":"2024-01-04T11:05:04.257089Z","shell.execute_reply":"2024-01-04T11:05:04.322756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking for missing values in Training dataset\ndf_train.isnull().sum().any()","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:04.325322Z","iopub.execute_input":"2024-01-04T11:05:04.325682Z","iopub.status.idle":"2024-01-04T11:05:04.541264Z","shell.execute_reply.started":"2024-01-04T11:05:04.325629Z","shell.execute_reply":"2024-01-04T11:05:04.540164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.loc[:, df_train.isna().any()].isna().sum().sort_values(ascending=False)","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:04.542826Z","iopub.execute_input":"2024-01-04T11:05:04.543229Z","iopub.status.idle":"2024-01-04T11:05:04.724331Z","shell.execute_reply.started":"2024-01-04T11:05:04.543201Z","shell.execute_reply":"2024-01-04T11:05:04.723388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.loc[:, df_test.isna().any()].isna().sum().sort_values(ascending=False)","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:04.725418Z","iopub.execute_input":"2024-01-04T11:05:04.725717Z","iopub.status.idle":"2024-01-04T11:05:04.810553Z","shell.execute_reply.started":"2024-01-04T11:05:04.725691Z","shell.execute_reply":"2024-01-04T11:05:04.809496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check null/missing values inside dataset in descending order\ndf_train.isnull().sum().sort_values(ascending=False)","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:04.811847Z","iopub.execute_input":"2024-01-04T11:05:04.812891Z","iopub.status.idle":"2024-01-04T11:05:04.99839Z","shell.execute_reply.started":"2024-01-04T11:05:04.812849Z","shell.execute_reply":"2024-01-04T11:05:04.997346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot missing values in Training dataset\nplt.figure(figsize = (16,6))\nsns.heatmap(df_train.isnull(), yticklabels= False, cbar= False, cmap='viridis')","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:04.999733Z","iopub.execute_input":"2024-01-04T11:05:05.001594Z","iopub.status.idle":"2024-01-04T11:05:13.963613Z","shell.execute_reply.started":"2024-01-04T11:05:05.001557Z","shell.execute_reply":"2024-01-04T11:05:13.962493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot missing values in Test dataset\nplt.figure(figsize = (16,6))\nsns.heatmap(df_test.isnull(), yticklabels= False, cbar= False, cmap='viridis')","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:13.965217Z","iopub.execute_input":"2024-01-04T11:05:13.965681Z","iopub.status.idle":"2024-01-04T11:05:17.568415Z","shell.execute_reply.started":"2024-01-04T11:05:13.965631Z","shell.execute_reply":"2024-01-04T11:05:17.567328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking for missing values in test dataset\ndf_test.isnull().sum().any()","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:17.570174Z","iopub.execute_input":"2024-01-04T11:05:17.570893Z","iopub.status.idle":"2024-01-04T11:05:17.653942Z","shell.execute_reply.started":"2024-01-04T11:05:17.570849Z","shell.execute_reply":"2024-01-04T11:05:17.652753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# find missing values in Training dataset according to their percentage\nmissing_perc = (df_train.isnull().sum()/len(df_train)*100).sort_values(ascending=False)\nmissing_perc[missing_perc != 0]","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:17.6552Z","iopub.execute_input":"2024-01-04T11:05:17.655517Z","iopub.status.idle":"2024-01-04T11:05:17.834103Z","shell.execute_reply.started":"2024-01-04T11:05:17.655488Z","shell.execute_reply":"2024-01-04T11:05:17.833078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the null values in Training Dataset by their percentage\nmissing_perc[missing_perc != 0].plot(kind='bar')\nplt.xlabel(\"Columns\")\nplt.ylabel(\"Percentage\")\nplt.title('Percentage of Missing Values in each columns')","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:17.835465Z","iopub.execute_input":"2024-01-04T11:05:17.835789Z","iopub.status.idle":"2024-01-04T11:05:18.12388Z","shell.execute_reply.started":"2024-01-04T11:05:17.835753Z","shell.execute_reply":"2024-01-04T11:05:18.122646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# find missing values in Test dataset according to their percentage\nmissing_perc_test = (df_test.isnull().sum()/len(df_test)*100).sort_values(ascending=False)\nmissing_perc_test[missing_perc_test != 0]","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:18.125574Z","iopub.execute_input":"2024-01-04T11:05:18.125928Z","iopub.status.idle":"2024-01-04T11:05:18.207026Z","shell.execute_reply.started":"2024-01-04T11:05:18.125898Z","shell.execute_reply":"2024-01-04T11:05:18.206012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the null values in Test Dataset by their percentage\nmissing_perc_test[missing_perc_test != 0].plot(kind='bar')\nplt.xlabel(\"Columns\")\nplt.ylabel(\"Percentage\")\nplt.title('Percentage of Missing Values in each columns')","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:18.208185Z","iopub.execute_input":"2024-01-04T11:05:18.208563Z","iopub.status.idle":"2024-01-04T11:05:18.460097Z","shell.execute_reply.started":"2024-01-04T11:05:18.208535Z","shell.execute_reply":"2024-01-04T11:05:18.459007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check any duplication\ndf_train.duplicated(subset=df_train.columns.difference(['case_id'])).any()","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:18.461394Z","iopub.execute_input":"2024-01-04T11:05:18.461732Z","iopub.status.idle":"2024-01-04T11:05:18.784879Z","shell.execute_reply.started":"2024-01-04T11:05:18.461702Z","shell.execute_reply":"2024-01-04T11:05:18.783906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.duplicated(subset=df_train.columns.difference(['case_id'])).sum()","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:18.790382Z","iopub.execute_input":"2024-01-04T11:05:18.79073Z","iopub.status.idle":"2024-01-04T11:05:19.134677Z","shell.execute_reply.started":"2024-01-04T11:05:18.7907Z","shell.execute_reply":"2024-01-04T11:05:19.13364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.duplicated(subset=df_train.columns).sum()","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:19.136048Z","iopub.execute_input":"2024-01-04T11:05:19.136578Z","iopub.status.idle":"2024-01-04T11:05:19.498988Z","shell.execute_reply.started":"2024-01-04T11:05:19.136548Z","shell.execute_reply":"2024-01-04T11:05:19.497762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.duplicated(subset=df_test.columns.difference(['case_id'])).sum()","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:19.500531Z","iopub.execute_input":"2024-01-04T11:05:19.501323Z","iopub.status.idle":"2024-01-04T11:05:19.635293Z","shell.execute_reply.started":"2024-01-04T11:05:19.501285Z","shell.execute_reply":"2024-01-04T11:05:19.634425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train[df_train.duplicated(subset=df_train.columns.difference(['case_id']), keep=False)]","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:19.636514Z","iopub.execute_input":"2024-01-04T11:05:19.637127Z","iopub.status.idle":"2024-01-04T11:05:20.008733Z","shell.execute_reply.started":"2024-01-04T11:05:19.637093Z","shell.execute_reply":"2024-01-04T11:05:20.007573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# Observation 3\n1. There are 65 duplicate rows in Training Dataset, which will make class imbalance, So We have to remove them.\n2. There are 28 duplicate rows in Test Dataset. It is not neccessary to remove duplication from test dataset ","metadata":{}},{"cell_type":"markdown","source":"# 4. Remove Anamolies from Dataset","metadata":{}},{"cell_type":"code","source":"df_train.drop_duplicates(subset=df_train.columns.difference(['case_id']), inplace=True)\nprint(df_train.shape)\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:20.01018Z","iopub.execute_input":"2024-01-04T11:05:20.010602Z","iopub.status.idle":"2024-01-04T11:05:20.44709Z","shell.execute_reply.started":"2024-01-04T11:05:20.010561Z","shell.execute_reply":"2024-01-04T11:05:20.446149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Mileston:\nDuplicate values are successfully removed from Training dataset","metadata":{}},{"cell_type":"code","source":"# first we have to check the dataset\ndf_train['Stay'].value_counts().sort_index()","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:20.448246Z","iopub.execute_input":"2024-01-04T11:05:20.448567Z","iopub.status.idle":"2024-01-04T11:05:20.484972Z","shell.execute_reply.started":"2024-01-04T11:05:20.448539Z","shell.execute_reply":"2024-01-04T11:05:20.483859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train[['Stay','Age']].value_counts().sort_index()","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:20.486234Z","iopub.execute_input":"2024-01-04T11:05:20.486556Z","iopub.status.idle":"2024-01-04T11:05:20.560127Z","shell.execute_reply.started":"2024-01-04T11:05:20.486526Z","shell.execute_reply":"2024-01-04T11:05:20.558921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['Age'].value_counts().sort_index()","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:20.56161Z","iopub.execute_input":"2024-01-04T11:05:20.562047Z","iopub.status.idle":"2024-01-04T11:05:20.597136Z","shell.execute_reply.started":"2024-01-04T11:05:20.562006Z","shell.execute_reply":"2024-01-04T11:05:20.595955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.columns","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:20.598507Z","iopub.execute_input":"2024-01-04T11:05:20.599593Z","iopub.status.idle":"2024-01-04T11:05:20.611846Z","shell.execute_reply.started":"2024-01-04T11:05:20.599552Z","shell.execute_reply":"2024-01-04T11:05:20.610706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['Severity of Illness'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:20.613111Z","iopub.execute_input":"2024-01-04T11:05:20.613457Z","iopub.status.idle":"2024-01-04T11:05:20.651653Z","shell.execute_reply.started":"2024-01-04T11:05:20.613428Z","shell.execute_reply":"2024-01-04T11:05:20.650416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['Department'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:20.653081Z","iopub.execute_input":"2024-01-04T11:05:20.65342Z","iopub.status.idle":"2024-01-04T11:05:20.688036Z","shell.execute_reply.started":"2024-01-04T11:05:20.653389Z","shell.execute_reply":"2024-01-04T11:05:20.68673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['Ward_Type'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:20.689716Z","iopub.execute_input":"2024-01-04T11:05:20.69034Z","iopub.status.idle":"2024-01-04T11:05:20.720917Z","shell.execute_reply.started":"2024-01-04T11:05:20.690295Z","shell.execute_reply":"2024-01-04T11:05:20.719621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['Bed Grade'].value_counts().sort_index()","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:20.722389Z","iopub.execute_input":"2024-01-04T11:05:20.722746Z","iopub.status.idle":"2024-01-04T11:05:20.737369Z","shell.execute_reply.started":"2024-01-04T11:05:20.722713Z","shell.execute_reply":"2024-01-04T11:05:20.735897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Check Unique values in all the columns along with maximum and minimum values in the Numerical columns","metadata":{}},{"cell_type":"code","source":"# Check Unique values, data type of each column and Minimum and Maximum values of Numerical columns\nfor column in df_train.columns:\n    unique_values = df_train[column].unique()\n    type_value = df_train[column].dtype\n    if len(unique_values) > 10:\n        unique_values = unique_values[:10]\n    total_unique_values = df_train[column].nunique()\n    print(f\"Data Type of {column}: {type_value}\")\n    print(f\"Total Unique values in {column}: {total_unique_values}\")\n    if (df_train[column].dtype == 'int64') or (df_train[column].dtype == 'float64'):\n       print(f\"Minimum value: {df_train[column].min()},   Maximum value: {df_train[column].max()}\")\n    print(f\"Unique values in {column}: {unique_values}\\n\")\n    ","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:20.739014Z","iopub.execute_input":"2024-01-04T11:05:20.739327Z","iopub.status.idle":"2024-01-04T11:05:21.248091Z","shell.execute_reply.started":"2024-01-04T11:05:20.739298Z","shell.execute_reply":"2024-01-04T11:05:21.246817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets separate Numerical and categorical columns to visualize properly\n\nnum_col_train = df_train.select_dtypes(include=np.number).columns.difference(['case_id','patientid'])\ncat_col_train = df_train.select_dtypes(include=['object','category']).columns\n# Visualize Numerical columns\n\nfor col in num_col_train:\n    print(col)\n    print(f\"Minimum value: {df_train[col].min()},   Maximum value: {df_train[col].max()}\")  \n    print('Skew :', round(df_train[col].skew(),2))\n    plt.figure(figsize = (15,4))\n    plt.subplot(1,2,1)\n    df_train[col].hist(grid = False)\n    # sns.histplot(data=df_train, x=df_train[col], kde=True)\n    plt.ylabel('Count')\n    plt.title(col)\n    plt.subplot(1,2,2)\n    plt.title(col)\n    sns.boxplot(x=df_train[col])\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:21.249589Z","iopub.execute_input":"2024-01-04T11:05:21.250003Z","iopub.status.idle":"2024-01-04T11:05:23.486977Z","shell.execute_reply.started":"2024-01-04T11:05:21.249971Z","shell.execute_reply":"2024-01-04T11:05:23.485836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print Categorical columns and their value counts\nprint(cat_col_train)\nfor i,col in enumerate(cat_col_train):\n    print(df_train[col].value_counts())\n    print('\\n')","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:23.488415Z","iopub.execute_input":"2024-01-04T11:05:23.489375Z","iopub.status.idle":"2024-01-04T11:05:23.79215Z","shell.execute_reply.started":"2024-01-04T11:05:23.489338Z","shell.execute_reply":"2024-01-04T11:05:23.790942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Distribution of all Categorical columns\ncat_col_train = df_train.select_dtypes(include=['object','category']).columns\nprint(f\"Categorical Columns are : {cat_col_train}\")\n# Visualize Categorical columns \nfig, axes = plt.subplots(nrows=6, ncols=2, figsize=(18, 26))\n# Increase vertical spacing\nplt.subplots_adjust(hspace=0.5)\n# Set the supertitle\nfig.suptitle('Bar plot for all categorical variables in the dataset with their Status\\n', fontsize=20)\n# Adjust the spacing between the supertitle and subplots\nplt.subplots_adjust(top=0.95)\n# Iterate over the columns and create count plots\nfor i, column in enumerate(cat_col_train):\n    row = i // 2\n    col = i % 2\n    sns.countplot(ax=axes[row, col], x=column, data=df_train) # , hue='Stay')\n   \n    total_count = len(df_train[column])\n\n    for p in axes[row,col].patches:\n        percentage = f'{100 * p.get_height() / total_count:.1f}%'\n        x_pos = p.get_x() + p.get_width() / 2\n        y_pos = p.get_height()\n        axes[row,col].annotate(percentage, (x_pos, y_pos), ha='center', va='bottom')\n# Adjust the layout and display the plots\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:23.793281Z","iopub.execute_input":"2024-01-04T11:05:23.793589Z","iopub.status.idle":"2024-01-04T11:05:29.691907Z","shell.execute_reply.started":"2024-01-04T11:05:23.793562Z","shell.execute_reply":"2024-01-04T11:05:29.690698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualization of correlation in numerical columns\nplt.figure(figsize=(12,8))\nsns.heatmap(df_train[num_col_train].corr(),cbar = True, cmap='coolwarm', annot=True)","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:29.693758Z","iopub.execute_input":"2024-01-04T11:05:29.694147Z","iopub.status.idle":"2024-01-04T11:05:30.116365Z","shell.execute_reply.started":"2024-01-04T11:05:29.694113Z","shell.execute_reply":"2024-01-04T11:05:30.115303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Figure-:** Shows the Correlation of all Numerical Columns ","metadata":{}},{"cell_type":"markdown","source":"---\n# Observation 4\nThere is no significance correlation in any numerical columns","metadata":{}},{"cell_type":"code","source":"import plotly.express as px\n# piechart\n\ndf_pie = df_train['Stay'].value_counts().reset_index()\ndf_pie.columns = ['Stay', 'count']\nfig_pie = px.pie(df_pie, values='count', names='Stay', title=\"Pie Plot showing distribution of the Length of Stay in the Hospital\") #, category_orders={'Stay':'0-10'})\n\nfig_pie.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:30.11831Z","iopub.execute_input":"2024-01-04T11:05:30.118806Z","iopub.status.idle":"2024-01-04T11:05:32.919927Z","shell.execute_reply.started":"2024-01-04T11:05:30.118726Z","shell.execute_reply":"2024-01-04T11:05:32.918625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# Observation 5\nMaximum  cases of patients (27.5%) staying in Hospital  for 21-30 days, at 2nd number more cases of patients (24.5%) staying for 11-20 days, at 3rd number cases of patients (17.3%) staying are 31-40 days as shown in above pie chart.","metadata":{}},{"cell_type":"code","source":"df_train.columns","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:32.921506Z","iopub.execute_input":"2024-01-04T11:05:32.921878Z","iopub.status.idle":"2024-01-04T11:05:32.928964Z","shell.execute_reply.started":"2024-01-04T11:05:32.921846Z","shell.execute_reply":"2024-01-04T11:05:32.928007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create sunburst plot on the dataset\n\n# Create a sunburst plot\n\nfig = px.sunburst(df_train, \n                  path=['Severity of Illness', 'Type of Admission','Department','Ward_Type', 'Stay'], \n                  values='Bed Grade' , color='Type of Admission', title=\"Chart shows the distribution of the Status \")\nfig.update_layout(width = 800, height= 800)\n# Show the plot\nfig.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:32.930148Z","iopub.execute_input":"2024-01-04T11:05:32.930947Z","iopub.status.idle":"2024-01-04T11:05:38.644829Z","shell.execute_reply.started":"2024-01-04T11:05:32.930908Z","shell.execute_reply":"2024-01-04T11:05:38.643746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.compose import ColumnTransformer\nfrom xgboost import XGBClassifier \n#import grid search cv for cross validation\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score, classification_report, log_loss, make_scorer","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:38.656498Z","iopub.execute_input":"2024-01-04T11:05:38.656963Z","iopub.status.idle":"2024-01-04T11:05:39.332893Z","shell.execute_reply.started":"2024-01-04T11:05:38.656923Z","shell.execute_reply":"2024-01-04T11:05:39.331881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train test split of dataset in python\nfrom sklearn.model_selection import train_test_split\n\n# Splitting the DataFrame into features (X) and target variable (y)\nX_train = df_train.drop(['Stay', 'case_id','patientid'], axis=1)  \ny_train = df_train['Stay']  \n\nX_test = df_test.drop(['case_id','patientid'], axis=1) \n\n# Splitting the data into train and test sets\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:39.334478Z","iopub.execute_input":"2024-01-04T11:05:39.334866Z","iopub.status.idle":"2024-01-04T11:05:39.421552Z","shell.execute_reply.started":"2024-01-04T11:05:39.334831Z","shell.execute_reply":"2024-01-04T11:05:39.420417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets separate Numerical and categorical columns to visualize properly\nnum_col = X_train.select_dtypes(include=np.number).columns\ncat_col = X_train.select_dtypes(include=['object']).columns","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:39.423456Z","iopub.execute_input":"2024-01-04T11:05:39.423851Z","iopub.status.idle":"2024-01-04T11:05:39.687612Z","shell.execute_reply.started":"2024-01-04T11:05:39.423818Z","shell.execute_reply":"2024-01-04T11:05:39.686452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a dictionaries of list of models to evaluate performance with hyperparameters\nmodels = { \n          'DecisionTreeClassifier' : (DecisionTreeClassifier(), {'criterion' : ['gini'],'max_depth': [None], 'splitter': ['best']}),\n          'RandomForestClass' : (RandomForestClassifier(n_jobs= -1), {'criterion' : ['gini'],'n_estimators': [10,100], 'max_depth': [None]}),\n          'AdaBoostClassifier' : (AdaBoostClassifier(), {'n_estimators': [10,100], 'algorithm': ['SAMME', 'SAMME.R']}),\n         # 'GradientBoostingClassifier' : (GradientBoostingClassifier(), {'criterion' : ['friedman_mse','squared_error'], 'n_estimators': [10]}),\n         # 'XGBClassifier' : (XGBClassifier(), {'n_estimators': [10], 'learning_rate': [0.1]}),          \n          }\n\n# Define the column transformer for preprocessing\npreprocessing = ColumnTransformer(\n    transformers=[\n        ('numeric', StandardScaler(), num_col),  # Replace with actual numeric column names\n        ('categorical', OneHotEncoder(), cat_col)  # Replace with actual categorical column name\n    ])\n\n# LogLoss = make_scorer(log_loss, greater_is_better=False, needs_proba=True)\n\nfor name, (model, params) in models.items():\n    # create a pipline\n    # pipeline = GridSearchCV(model, params, cv=5)\n    pipeline = Pipeline([\n     ('preprocess', preprocessing),\n     ('Imputer', SimpleImputer()),\n     ('classify', GridSearchCV(model, params, cv=5, verbose=3))\n    ])\n    # fit the pipeline\n    pipeline.fit(X_train, y_train)\n    \n    # make prediction from each model\n    y_pred = pipeline.predict(X_test)\n    \n    y_pred_prob = pipeline.predict_proba(X_test)\n    # print the performing metric\n    # Calculate accuracy\n    print(f\"Model Name: {name}\")\n    print(\"Best Parameters: \", pipeline.named_steps['classify'].best_params_)\n    print(\"Best Score: \", pipeline.named_steps['classify'].best_score_)\n    print(\"Best Estimator: \", pipeline.named_steps['classify'].best_estimator_)\n   ","metadata":{"execution":{"iopub.status.busy":"2024-01-04T11:05:39.689069Z","iopub.execute_input":"2024-01-04T11:05:39.689821Z","iopub.status.idle":"2024-01-04T11:36:44.86216Z","shell.execute_reply.started":"2024-01-04T11:05:39.689776Z","shell.execute_reply":"2024-01-04T11:36:44.860746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"---\n# Conclusion:\nAdaBoostClassifier provided best accuracy score as compare to RandomForestClassifier","metadata":{}}]}